{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90000, 90001]\n",
      "[{'self': 'https://qosmos.atlassian.net/rest/api/3/issue/253770/worklog/90001', 'author': {'self': 'https://qosmos.atlassian.net/rest/api/3/user?accountId=557058%3Accd9776e-f678-4bc4-88ea-54a6d2ae688f', 'accountId': '557058:ccd9776e-f678-4bc4-88ea-54a6d2ae688f', 'emailAddress': 'labruyere@qosmos.com', 'avatarUrls': {'48x48': 'https://secure.gravatar.com/avatar/76ad4ed19b08326798ad20e97dc280e5?d=https%3A%2F%2Favatar-management--avatars.us-west-2.prod.public.atl-paas.net%2Finitials%2FHL-3.png', '24x24': 'https://secure.gravatar.com/avatar/76ad4ed19b08326798ad20e97dc280e5?d=https%3A%2F%2Favatar-management--avatars.us-west-2.prod.public.atl-paas.net%2Finitials%2FHL-3.png', '16x16': 'https://secure.gravatar.com/avatar/76ad4ed19b08326798ad20e97dc280e5?d=https%3A%2F%2Favatar-management--avatars.us-west-2.prod.public.atl-paas.net%2Finitials%2FHL-3.png', '32x32': 'https://secure.gravatar.com/avatar/76ad4ed19b08326798ad20e97dc280e5?d=https%3A%2F%2Favatar-management--avatars.us-west-2.prod.public.atl-paas.net%2Finitials%2FHL-3.png'}, 'displayName': 'Harold Labruyere', 'active': True, 'timeZone': 'Europe/Paris', 'accountType': 'atlassian'}, 'updateAuthor': {'self': 'https://qosmos.atlassian.net/rest/api/3/user?accountId=557058%3Accd9776e-f678-4bc4-88ea-54a6d2ae688f', 'accountId': '557058:ccd9776e-f678-4bc4-88ea-54a6d2ae688f', 'emailAddress': 'labruyere@qosmos.com', 'avatarUrls': {'48x48': 'https://secure.gravatar.com/avatar/76ad4ed19b08326798ad20e97dc280e5?d=https%3A%2F%2Favatar-management--avatars.us-west-2.prod.public.atl-paas.net%2Finitials%2FHL-3.png', '24x24': 'https://secure.gravatar.com/avatar/76ad4ed19b08326798ad20e97dc280e5?d=https%3A%2F%2Favatar-management--avatars.us-west-2.prod.public.atl-paas.net%2Finitials%2FHL-3.png', '16x16': 'https://secure.gravatar.com/avatar/76ad4ed19b08326798ad20e97dc280e5?d=https%3A%2F%2Favatar-management--avatars.us-west-2.prod.public.atl-paas.net%2Finitials%2FHL-3.png', '32x32': 'https://secure.gravatar.com/avatar/76ad4ed19b08326798ad20e97dc280e5?d=https%3A%2F%2Favatar-management--avatars.us-west-2.prod.public.atl-paas.net%2Finitials%2FHL-3.png'}, 'displayName': 'Harold Labruyere', 'active': True, 'timeZone': 'Europe/Paris', 'accountType': 'atlassian'}, 'created': '2020-11-02T10:24:34.767+0100', 'updated': '2020-11-02T10:24:34.767+0100', 'started': '2020-10-28T09:24:00.000+0100', 'timeSpent': '1h', 'timeSpentSeconds': 3600, 'id': '90001', 'issueId': '253770'}, {'self': 'https://qosmos.atlassian.net/rest/api/3/issue/250122/worklog/90000', 'author': {'self': 'https://qosmos.atlassian.net/rest/api/3/user?accountId=557058%3Accd9776e-f678-4bc4-88ea-54a6d2ae688f', 'accountId': '557058:ccd9776e-f678-4bc4-88ea-54a6d2ae688f', 'emailAddress': 'labruyere@qosmos.com', 'avatarUrls': {'48x48': 'https://secure.gravatar.com/avatar/76ad4ed19b08326798ad20e97dc280e5?d=https%3A%2F%2Favatar-management--avatars.us-west-2.prod.public.atl-paas.net%2Finitials%2FHL-3.png', '24x24': 'https://secure.gravatar.com/avatar/76ad4ed19b08326798ad20e97dc280e5?d=https%3A%2F%2Favatar-management--avatars.us-west-2.prod.public.atl-paas.net%2Finitials%2FHL-3.png', '16x16': 'https://secure.gravatar.com/avatar/76ad4ed19b08326798ad20e97dc280e5?d=https%3A%2F%2Favatar-management--avatars.us-west-2.prod.public.atl-paas.net%2Finitials%2FHL-3.png', '32x32': 'https://secure.gravatar.com/avatar/76ad4ed19b08326798ad20e97dc280e5?d=https%3A%2F%2Favatar-management--avatars.us-west-2.prod.public.atl-paas.net%2Finitials%2FHL-3.png'}, 'displayName': 'Harold Labruyere', 'active': True, 'timeZone': 'Europe/Paris', 'accountType': 'atlassian'}, 'updateAuthor': {'self': 'https://qosmos.atlassian.net/rest/api/3/user?accountId=557058%3Accd9776e-f678-4bc4-88ea-54a6d2ae688f', 'accountId': '557058:ccd9776e-f678-4bc4-88ea-54a6d2ae688f', 'emailAddress': 'labruyere@qosmos.com', 'avatarUrls': {'48x48': 'https://secure.gravatar.com/avatar/76ad4ed19b08326798ad20e97dc280e5?d=https%3A%2F%2Favatar-management--avatars.us-west-2.prod.public.atl-paas.net%2Finitials%2FHL-3.png', '24x24': 'https://secure.gravatar.com/avatar/76ad4ed19b08326798ad20e97dc280e5?d=https%3A%2F%2Favatar-management--avatars.us-west-2.prod.public.atl-paas.net%2Finitials%2FHL-3.png', '16x16': 'https://secure.gravatar.com/avatar/76ad4ed19b08326798ad20e97dc280e5?d=https%3A%2F%2Favatar-management--avatars.us-west-2.prod.public.atl-paas.net%2Finitials%2FHL-3.png', '32x32': 'https://secure.gravatar.com/avatar/76ad4ed19b08326798ad20e97dc280e5?d=https%3A%2F%2Favatar-management--avatars.us-west-2.prod.public.atl-paas.net%2Finitials%2FHL-3.png'}, 'displayName': 'Harold Labruyere', 'active': True, 'timeZone': 'Europe/Paris', 'accountType': 'atlassian'}, 'created': '2020-11-02T10:16:28.390+0100', 'updated': '2020-11-02T10:16:28.390+0100', 'started': '2020-10-28T09:16:00.000+0100', 'timeSpent': '1h', 'timeSpentSeconds': 3600, 'id': '90000', 'issueId': '250122'}]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-11aeb231b02f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"JIRA_SERVER\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://qosmos.atlassian.net/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJiraClient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"labruyere@qosmos.com\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"CyeOhFd99Eog7YSxAWRqA886\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m \u001b[0mrecent_worklogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve_worklogs_updated_since\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-11aeb231b02f>\u001b[0m in \u001b[0;36mretrieve_worklogs_updated_since\u001b[1;34m(self, start)\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mworklogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworklog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworklogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworklogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Remove duplicates returned by the Jira API\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msearch_issues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjql\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Any, Dict, Generator, List, Union\n",
    "\n",
    "import requests\n",
    "# Optional - to connect using OAuth credentials\n",
    "from oauthlib.oauth1 import SIGNATURE_RSA\n",
    "\n",
    "class JiraClient:\n",
    "    def __init__(\n",
    "        self,\n",
    "        username: str = None,\n",
    "        api_token: str = None,\n",
    "        access_token: str = None,\n",
    "        access_token_secret: str = None,\n",
    "        consumer_key: str = None,\n",
    "        key_cert: str = None,\n",
    "    ):\n",
    "        self._user_url = os.getenv(\"JIRA_SERVER\", \"\").rstrip(\"/\")\n",
    "        self._base_url = f\"{self._user_url}/rest/api/3\"\n",
    "\n",
    "        if username and api_token:\n",
    "            self._session = requests.Session()\n",
    "            self._session.auth = (username, api_token)\n",
    "            return\n",
    "        elif access_token and access_token_secret and consumer_key and key_cert:\n",
    "            self._session = OAuth1Session(\n",
    "                consumer_key,\n",
    "                rsa_key=key_cert,\n",
    "                resource_owner_key=access_token,\n",
    "                resource_owner_secret=access_token_secret,\n",
    "                signature_method=SIGNATURE_RSA,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Must use API token or OAuth credentials\")\n",
    "    \n",
    "    def _get_paginated_results(\n",
    "        self, url: str, results_key: str, parameters: Dict[str, Union[str, int]] = None, use_post: bool = False,\n",
    "    ) -> Generator[Dict[str, Any], None, None]:\n",
    "        \"\"\"Get results of a paginated call that uses 'maxResults', 'startAt', and 'total' attributes.\n",
    "        :param url: URL without any pagination parameters\n",
    "        :param results_key: The key of the response dict that contains the actual elements to return (varies from calls to calls). Ex.: \"items\"\n",
    "        :param parameters: If use_post is False, URL parameters. If use_post is True, json encoded body parameters\n",
    "        :param use_post: Use POST instead of GET. Needed if parameters are too long to fit in an URL\n",
    "        \"\"\"\n",
    "        parameters = parameters or {}\n",
    "\n",
    "        results_per_page = 1000\n",
    "        parameters[\"maxResults\"] = results_per_page\n",
    "        next = 0\n",
    "        while True:\n",
    "            parameters[\"startAt\"] = next\n",
    "            if use_post:\n",
    "                response = self._session.post(url, json=parameters)\n",
    "            else:\n",
    "                response = self._session.get(url, params=parameters)\n",
    "            response.raise_for_status()\n",
    "            response_json = response.json()\n",
    "            results = response_json[results_key]\n",
    "\n",
    "            if response_json[\"maxResults\"] < results_per_page:\n",
    "                # Some calls limit the maximum value of maxResults\n",
    "                results_per_page = response_json[\"maxResults\"]\n",
    "                parameters[\"maxResults\"] = results_per_page\n",
    "\n",
    "            for result in results:\n",
    "                yield result\n",
    "\n",
    "            next += results_per_page\n",
    "            if next >= response_json[\"total\"]:\n",
    "                return\n",
    "            \n",
    "    def _get_paginated_results_with_next_page_link(self, url: str) -> Generator[Dict[str, Any], None, None]:\n",
    "        \"\"\"Get results of a call that returns a payload with the lastPage and nextPage attributes\"\"\"\n",
    "        is_last_page = False\n",
    "        while not is_last_page:\n",
    "            response = self._session.get(url)\n",
    "            response.raise_for_status()\n",
    "            response_json = response.json()\n",
    "            for result in response_json[\"values\"]:\n",
    "                yield result\n",
    "\n",
    "            is_last_page = response_json.get(\"lastPage\", True)\n",
    "            if not is_last_page:\n",
    "                url = response_json[\"nextPage\"]\n",
    "\n",
    "    def retrieve_worklogs_updated_since(self, start: datetime) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Retrieve worklog objects for all worklogs that have been created or updated since the provided datetime\n",
    "        Faster than getting worklogs through issues\n",
    "        \"\"\"\n",
    "        worklog_ids: List[str] = []\n",
    "        for worklog_entry in self._get_paginated_results_with_next_page_link(\n",
    "            f\"{self._base_url}/worklog/updated?since={int(start.timestamp() * 1000)}\"\n",
    "        ):\n",
    "            worklog_ids.append(worklog_entry[\"worklogId\"])\n",
    "        print(worklog_ids)\n",
    "        worklogs_per_page = 1000\n",
    "        ids_in_groups_per_page = [worklog_ids[i : i + worklogs_per_page] for i in range(0, len(worklog_ids), worklogs_per_page)]\n",
    "        worklogs: List[Dict[str, Any]] = []\n",
    "        # This is kind of a manual pagination. The documentation only states \"The returned list of worklogs is limited to 1000 items.\"\n",
    "        # Doc: https://developer.atlassian.com/cloud/jira/platform/rest/v3/#api-rest-api-3-worklog-list-post\n",
    "        for ids_to_get in ids_in_groups_per_page:\n",
    "            for worklog in self._session.post(f\"{self._base_url}/worklog/list\", json={\"ids\": ids_to_get}).json():\n",
    "                # Optionnaly remove the worklogs you don't want (not in the right time period)\n",
    "                worklogs.append(worklog)\n",
    "        print(worklogs)\n",
    "        return list(set(worklogs))  # Remove duplicates returned by the Jira API\n",
    "    \n",
    "    def search_issues(self, jql: str, fields: List[str] = None) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Return issues that matches a specified JQL query\"\"\"\n",
    "        issues: List[Dict[str, Any]] = []\n",
    "        parameters: Dict[str, Union[str, List[str]]] = {\"jql\": jql}\n",
    "        if fields:\n",
    "            parameters[\"fields\"] = fields\n",
    "        for issue in self._get_paginated_results(f\"{self._base_url}/search\", parameters=parameters, results_key=\"issues\", use_post=True):\n",
    "            issues.append(issue)\n",
    "\n",
    "        return issues\n",
    "    \n",
    "    # Point 3 - get issues for the retrieved worklogs\n",
    "    def retrieve_issues_for_worklogs(self, worklogs: List[Dict[str, Any]], fields: List[str] = None) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Get Issue objects referenced in a list of worklogs\"\"\"\n",
    "        return self.search_issues(f\"id in ({','.join(str(issue_id) for issue_id in set(worklog['issueId'] for worklog in worklogs))})\", fields=fields)\n",
    "     \n",
    "    \n",
    "# Example usage\n",
    "os.environ[\"JIRA_SERVER\"] = \"https://qosmos.atlassian.net/\"\n",
    "client = JiraClient(\"labruyere@qosmos.com\", \"CyeOhFd99Eog7YSxAWRqA886\")\n",
    "recent_worklogs = client.retrieve_worklogs_updated_since(datetime.now() - timedelta(days=14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recent_worklogs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
